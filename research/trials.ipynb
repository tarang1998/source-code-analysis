{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "\n",
    "# Loading the repo \n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.git import GitLoader\n",
    "\n",
    "# Parsing through the documents to create chunks\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "GitCommandError",
     "evalue": "Cmd('git') failed due to: exit code(128)\n  cmdline: git clone -v -- https://github.com/tarang1998/bodyScienceLLM test_repo/\n  stderr: 'fatal: destination path 'test_repo' already exists and is not an empty directory.\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGitCommandError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m repo_path = \u001b[33m\"\u001b[39m\u001b[33mtest_repo/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m repo_link = \u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/tarang1998/bodyScienceLLM\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m repo = \u001b[43mRepo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tarang\\source-code-analysis\\venv\\Lib\\site-packages\\git\\repo\\base.py:1541\u001b[39m, in \u001b[36mRepo.clone_from\u001b[39m\u001b[34m(cls, url, to_path, progress, env, multi_options, allow_unsafe_protocols, allow_unsafe_options, **kwargs)\u001b[39m\n\u001b[32m   1539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1540\u001b[39m     git.update_environment(**env)\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mto_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mGitCmdObjectDB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unsafe_protocols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_unsafe_protocols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unsafe_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_unsafe_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tarang\\source-code-analysis\\venv\\Lib\\site-packages\\git\\repo\\base.py:1412\u001b[39m, in \u001b[36mRepo._clone\u001b[39m\u001b[34m(cls, git, url, path, odb_default_type, progress, multi_options, allow_unsafe_protocols, allow_unsafe_options, **kwargs)\u001b[39m\n\u001b[32m   1409\u001b[39m     cmdline = remove_password_if_present(cmdline)\n\u001b[32m   1411\u001b[39m     _logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCmd(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms unused stdout: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, cmdline, stdout)\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m     \u001b[43mfinalize_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1414\u001b[39m \u001b[38;5;66;03m# Our git command could have a different working dir than our actual\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[38;5;66;03m# environment, hence we prepend its working dir if required.\u001b[39;00m\n\u001b[32m   1416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m osp.isabs(path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tarang\\source-code-analysis\\venv\\Lib\\site-packages\\git\\util.py:504\u001b[39m, in \u001b[36mfinalize_process\u001b[39m\u001b[34m(proc, **kwargs)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Wait for the process (clone, fetch, pull or push) and handle its errors\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[33;03maccordingly.\"\"\"\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[38;5;66;03m# TODO: No close proc-streams??\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Tarang\\source-code-analysis\\venv\\Lib\\site-packages\\git\\cmd.py:834\u001b[39m, in \u001b[36mGit.AutoInterrupt.wait\u001b[39m\u001b[34m(self, stderr)\u001b[39m\n\u001b[32m    832\u001b[39m     errstr = read_all_from_possibly_closed_stream(p_stderr)\n\u001b[32m    833\u001b[39m     _logger.debug(\u001b[33m\"\u001b[39m\u001b[33mAutoInterrupt wait stderr: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % (errstr,))\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GitCommandError(remove_password_if_present(\u001b[38;5;28mself\u001b[39m.args), status, errstr)\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m status\n",
      "\u001b[31mGitCommandError\u001b[39m: Cmd('git') failed due to: exit code(128)\n  cmdline: git clone -v -- https://github.com/tarang1998/bodyScienceLLM test_repo/\n  stderr: 'fatal: destination path 'test_repo' already exists and is not an empty directory.\n'"
     ]
    }
   ],
   "source": [
    "repo_path = \"test_repo/\"\n",
    "repo_link = \"https://github.com/tarang1998/bodyScienceLLM\"\n",
    "repo = Repo.clone_from(repo_link, to_path=repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define supported programming languages and their file extensions\n",
    "SUPPORTED_LANGUAGES =  {\n",
    "    Language.PYTHON: {\n",
    "        'suffixes': ['.py', '.pyx', '.pyi'],\n",
    "        'language': Language.PYTHON\n",
    "    },\n",
    "    Language.JS: {\n",
    "        'suffixes': ['.js', '.jsx', '.ts', '.tsx'],\n",
    "        'language': Language.JS\n",
    "    },\n",
    "    Language.JAVA: {\n",
    "        'suffixes': ['.java'],\n",
    "        'language': Language.JAVA\n",
    "    },\n",
    "    Language.CPP: {\n",
    "        'suffixes': ['.cpp', '.cc', '.cxx', '.h', '.hpp'],\n",
    "        'language': Language.CPP\n",
    "    },\n",
    "    Language.CSHARP: {\n",
    "        'suffixes': ['.cs'],\n",
    "        'language': Language.CSHARP\n",
    "    },\n",
    "    Language.PHP: {\n",
    "        'suffixes': ['.php'],\n",
    "        'language': Language.PHP\n",
    "    },\n",
    "    Language.RUBY: {\n",
    "        'suffixes': ['.rb'],\n",
    "        'language': Language.RUBY\n",
    "    },\n",
    "    Language.RUST: {\n",
    "        'suffixes': ['.rs'],\n",
    "        'language': Language.RUST\n",
    "    },\n",
    "    Language.GO: {\n",
    "        'suffixes': ['.go'],\n",
    "        'language': Language.GO\n",
    "    },\n",
    "    Language.SCALA: {\n",
    "        'suffixes': ['.scala'],\n",
    "        'language': Language.SCALA\n",
    "    },\n",
    "    Language.KOTLIN: {\n",
    "        'suffixes': ['.kt', '.kts'],\n",
    "        'language': Language.KOTLIN\n",
    "    },\n",
    "    Language.LUA: {\n",
    "        'suffixes': ['.lua'],\n",
    "        'language': Language.LUA\n",
    "    },\n",
    "    Language.PERL: {\n",
    "        'suffixes': ['.pl', '.pm'],\n",
    "        'language': Language.PERL\n",
    "    },\n",
    "    Language.ELIXIR: {\n",
    "        'suffixes': ['.ex', '.exs'],\n",
    "        'language': Language.ELIXIR\n",
    "    },\n",
    "    Language.COBOL: {\n",
    "        'suffixes': ['.cob', '.cbl'],\n",
    "        'language': Language.COBOL\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text and document files (use default chunking)\n",
    "TEXT_FILES = {\n",
    "    '.txt', '.md', '.markdown', '.rst', '.adoc', '.asciidoc',\n",
    "    '.json', '.yaml', '.yml', '.toml', '.ini', '.cfg', '.conf',\n",
    "    '.html', '.htm', '.css', '.scss', '.sass',\n",
    "    '.csv', '.tsv', '.xml', '.rss', '.atom',\n",
    "    '.mdx', '.log', '.readme', '.license', '.changelog',\n",
    "    '.dockerfile', '.dockerignore', '.gitignore', '.gitattributes',\n",
    "    '.env', '.env.example', '.env.local',\n",
    "    '.sh', '.bash', '.zsh', '.fish',  # Shell scripts\n",
    "    '.sql', '.psql', '.mysql',  # SQL files\n",
    "    '.dockerfile', '.docker-compose.yml', '.docker-compose.yaml',\n",
    "    '.yaml', '.yml',  # YAML files\n",
    "    '.json', '.jsonc',  # JSON files\n",
    "    '.xml', '.xsd', '.xslt',  # XML files\n",
    "    '.html', '.htm', '.xhtml',  # HTML files\n",
    "    '.css', '.scss', '.sass', '.less',  # CSS files\n",
    "    '.md', '.markdown', '.mdown',  # Markdown files\n",
    "    '.txt', '.text',  # Plain text files\n",
    "    '.log', '.out', '.err',  # Log files\n",
    "    '.ini', '.cfg', '.conf', '.config',  # Config files\n",
    "    '.toml', '.lock',  # TOML files\n",
    "    '.rss', '.atom', '.feed',  # Feed files\n",
    "    '.csv', '.tsv', '.tab',  # Data files\n",
    "    '.readme', '.license', '.changelog', '.contributing',  # Documentation\n",
    "    '.gitignore', '.gitattributes', '.gitmodules',  # Git files\n",
    "    '.dockerignore', '.dockerfile',  # Docker files\n",
    "    '.env', '.env.example', '.env.local', '.env.production',  # Environment files\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_extension(file_path):\n",
    "    \"\"\"Extract file extension from path\"\"\"\n",
    "    return os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "def create_language_filter(languages=None):\n",
    "    \"\"\"Create a file filter for specified languages\"\"\"\n",
    "    if languages is None:\n",
    "        # Include all supported extensions\n",
    "        allowed_extensions = []\n",
    "        for value in SUPPORTED_LANGUAGES.values():\n",
    "            allowed_extensions.extend(value[\"suffixes\"])\n",
    "\n",
    "        allowed_extensions.extend(TEXT_FILES)\n",
    "    else:\n",
    "        # Include only specified languages\n",
    "        allowed_extensions = []\n",
    "        for lang in languages:\n",
    "            if lang in SUPPORTED_LANGUAGES:\n",
    "                allowed_extensions.extend(SUPPORTED_LANGUAGES[lang][\"suffixes\"])\n",
    "            elif lang == \"TEXT\":\n",
    "                allowed_extensions.extend(TEXT_FILES)\n",
    "    def file_filter(file_path):\n",
    "        return get_file_extension(file_path) in allowed_extensions\n",
    "    \n",
    "    return file_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 PYTHON files\n",
      "[Document(metadata={'source': 'test_repo\\\\ test.py', 'language': <Language.PYTHON: 'python'>}, page_content=''), Document(metadata={'source': 'test_repo\\\\app.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}, page_content=\"def index():\\n    return render_template('chat.html')\"), Document(metadata={'source': 'test_repo\\\\app.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}, page_content='def chat():\\n    msg = request.form[\"msg\"]\\n    input = msg\\n    print(input)\\n    response = rag_chain.invoke({\"input\": msg})\\n    print(\"Response : \", response[\"answer\"])\\n    return str(response[\"answer\"])'), Document(metadata={'source': 'test_repo\\\\app.py', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}, page_content='from flask import Flask, render_template, jsonify, request\\nfrom src.helper import download_hugging_face_embeddings\\nfrom langchain_pinecone import PineconeVectorStore\\nfrom langchain_openai import OpenAI\\nfrom langchain.chains import create_retrieval_chain\\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom dotenv import load_dotenv\\nfrom src.prompt import *\\nimport os\\n\\napp = Flask(__name__)\\n\\nload_dotenv()\\n\\nPINECONE_API_KEY=os.environ.get(\\'PINECONE_API_KEY\\')\\nOPENAI_API_KEY=os.environ.get(\\'OPENAI_API_KEY\\')\\n\\nos.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\\n\\nembeddings = download_hugging_face_embeddings()\\n\\n\\nindex_name = \"bodybuildingchatbot\"\\n\\n# Embed each chunk and upsert the embeddings into your Pinecone index.\\ndocsearch = PineconeVectorStore.from_existing_index(\\n    index_name=index_name,\\n    embedding=embeddings\\n)\\n\\nretriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\\n\\n\\nllm = OpenAI(temperature=0.4, max_tokens=500)\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{input}\"),\\n    ]\\n)\\n\\nquestion_answer_chain = create_stuff_documents_chain(llm, prompt)\\nrag_chain = create_retrieval_chain(retriever, question_answer_chain)\\n\\n\\n@app.route(\"/\")\\n# Code for: def index():\\n\\n\\n@app.route(\"/get\", methods=[\"GET\", \"POST\"]) \\n# Code for: def chat():\\n\\n\\n\\n\\nif __name__ == \\'__main__\\':\\n    app.run(host=\"0.0.0.0\", port= 8080, debug= True)'), Document(metadata={'source': 'test_repo\\\\setup.py', 'language': <Language.PYTHON: 'python'>}, page_content=\"from setuptools import find_packages, setup\\n\\nsetup(\\n    name = 'BodyScienceLLM',\\n    version= '0.0.0',\\n    author= 'Tarang Nair',\\n    author_email= 'tarangnair98@gmail.com',\\n    packages= find_packages(),\\n    install_requires = []\\n)\"), Document(metadata={'source': 'test_repo\\\\store_index.py', 'language': <Language.PYTHON: 'python'>}, page_content='from src.helper import load_pdf_file, text_split, download_hugging_face_embeddings\\nfrom pinecone import Pinecone,ServerlessSpec\\nfrom langchain_pinecone import PineconeVectorStore\\nfrom dotenv import load_dotenv\\nimport os\\n\\n\\nload_dotenv()\\n\\nPINECONE_API_KEY=os.environ.get(\\'PINECONE_API_KEY\\')\\nos.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\\n\\n\\nextracted_data=load_pdf_file(data=\\'data/\\')\\ntext_chunks=text_split(extracted_data)\\nembeddings = download_hugging_face_embeddings()\\n\\n\\npc = Pinecone(api_key=PINECONE_API_KEY)\\n\\nindex_name = \"bodybuildingchatbot\"\\n\\n\\npc.create_index(\\n    name=index_name,\\n    dimension=384,  # Output Dimensions From the embedding model \\n    metric=\"cosine\", \\n    spec=ServerlessSpec(\\n        cloud=\"aws\", \\n        region=\"us-east-1\"\\n    ) \\n) \\n\\n# Embed each chunk and upsert the embeddings into your Pinecone index.\\ndocsearch = PineconeVectorStore.from_documents(\\n    documents=text_chunks,\\n    index_name=index_name,\\n    embedding=embeddings, \\n)\\n'), Document(metadata={'source': 'test_repo\\\\template.py', 'language': <Language.PYTHON: 'python'>}, page_content='import os\\nfrom pathlib import Path\\nimport logging\\n\\nlogging.basicConfig(level=logging.INFO, format=\\'[%(asctime)s]: %(message)s:\\')\\n\\n\\nlist_of_files = [\\n    \"src/__init__.py\",\\n    \"src/helper.py\",\\n    \"src/prompt.py\",\\n    \".env\",\\n    \"setup.py\",\\n    \"app.py\",\\n    \"research/trials.ipynb\",\\n]\\n\\n\\nfor filepath in list_of_files:\\n    filepath = Path(filepath)\\n    filedir, filename = os.path.split(filepath)\\n\\n\\n    if filedir !=\"\":\\n        os.makedirs(filedir, exist_ok=True)\\n        logging.info(f\"Creating directory; {filedir} for the file: {filename}\")\\n\\n    if (not os.path.exists(filepath)) or (os.path.getsize(filepath) == 0):\\n        with open(filepath, \"w\") as f:\\n            pass\\n            logging.info(f\"Creating empty file: {filepath}\")\\n\\n\\n    else:\\n        logging.info(f\"{filename} is already exists\")'), Document(metadata={'source': 'test_repo\\\\src\\\\helper.py', 'language': <Language.PYTHON: 'python'>}, page_content='\\nfrom langchain_community.document_loaders import DirectoryLoader\\nfrom langchain_community.document_loaders import PyPDFLoader\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain_huggingface import HuggingFaceEmbeddings\\n\\n\\n\\n#Extract Data From the PDF File\\ndef load_pdf_file(data):\\n    loader= DirectoryLoader(data,\\n                            glob=\"*.pdf\",\\n                            loader_cls=PyPDFLoader)\\n\\n    documents=loader.load()\\n\\n    return documents\\n\\n\\n\\n#Split the Data into Text Chunks\\ndef text_split(extracted_data):\\n    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\\n    text_chunks=text_splitter.split_documents(extracted_data)\\n    return text_chunks\\n\\n\\n\\n#Download the Embeddings from HuggingFace \\ndef download_hugging_face_embeddings():\\n    embeddings=HuggingFaceEmbeddings(model_name=\\'sentence-transformers/all-MiniLM-L6-v2\\')  #this model return 384 dimensions\\n    return embeddings'), Document(metadata={'source': 'test_repo\\\\src\\\\prompt.py', 'language': <Language.PYTHON: 'python'>}, page_content='\\n\\nsystem_prompt = (\\n    \"You are an assistant for question-answering tasks. \"\\n    \"Use the following pieces of retrieved context to answer \"\\n    \"the question. If you don\\'t know the answer, say that you \"\\n    \"don\\'t know. Use three sentences maximum and keep the \"\\n    \"answer concise.\"\\n    \"\\\\n\\\\n\"\\n    \"{context}\"\\n)\\n'), Document(metadata={'source': 'test_repo\\\\src\\\\__init__.py', 'language': <Language.PYTHON: 'python'>}, page_content='')]\n",
      "Loaded 0 JS files\n",
      "[]\n",
      "Loaded 0 JAVA files\n",
      "[]\n",
      "Loaded 0 CPP files\n",
      "[]\n",
      "Loaded 0 CSHARP files\n",
      "[]\n",
      "Loaded 0 PHP files\n",
      "[]\n",
      "Loaded 0 RUBY files\n",
      "[]\n",
      "Loaded 0 RUST files\n",
      "[]\n",
      "Loaded 0 GO files\n",
      "[]\n",
      "Loaded 0 SCALA files\n",
      "[]\n",
      "Loaded 0 KOTLIN files\n",
      "[]\n",
      "Loaded 0 LUA files\n",
      "[]\n",
      "Loaded 0 PERL files\n",
      "[]\n",
      "Loaded 0 ELIXIR files\n",
      "[]\n",
      "Loaded 0 COBOL files\n",
      "[]\n",
      "Total documents loaded: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load documents for each language\n",
    "all_documents = []\n",
    "\n",
    "for language, config in SUPPORTED_LANGUAGES.items():\n",
    "    try:\n",
    "        loader = GenericLoader.from_filesystem(\n",
    "            repo_path,\n",
    "            glob=\"**/*\",\n",
    "            suffixes=config['suffixes'],\n",
    "            parser=LanguageParser(\n",
    "                language=config['language'],\n",
    "                parser_threshold=50\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        documents = loader.load()\n",
    "        all_documents.extend(documents)\n",
    "        print(f\"Loaded {len(documents)} {language.name} files\")\n",
    "        print(documents)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {language.name} files: {e}\")\n",
    "\n",
    "print(f\"Total documents loaded: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': ' test.py', 'file_path': ' test.py', 'file_name': ' test.py', 'file_type': '.py'}, page_content=''),\n",
       " Document(metadata={'source': 'README.md', 'file_path': 'README.md', 'file_name': 'README.md', 'file_type': '.md'}, page_content='# BodyScienceLLM\\r\\n\\r\\n![alt text](./screenshots/image.png)\\r\\n\\r\\n### Techology and Tools used\\r\\n- Python (version 3.9)\\r\\n- Lang Chain \\r\\n- Hugging Face Embedding Model \\r\\n- PineCone\\r\\n- OpenAI \\r\\n- Flask\\r\\n\\r\\n### Running the application\\r\\n\\r\\n- Clone the repository\\r\\n```\\r\\ngit clone https://github.com/tarang1998/bodyScienceLLM.git\\r\\n```\\r\\n- Create and activate the python environment\\r\\n\\r\\n```\\r\\nconda create -n bodyScience python=3.10 -y\\r\\nconda activate bodyScience\\r\\n```\\r\\n\\r\\n- Install the requirements \\r\\n```\\r\\npip install -r requirements.txt\\r\\n```\\r\\n\\r\\n- Add the OPENAI_API_KEY and PINECONE_API_KEY in the .env file \\r\\n\\r\\n- Save the vector embeddings to Pinecone\\r\\n```\\r\\npython store_index.py\\r\\n```\\r\\n\\r\\n- Run the flask application\\r\\n```\\r\\npython app.py\\r\\n```\\r\\n\\r\\n'),\n",
       " Document(metadata={'source': 'app.py', 'file_path': 'app.py', 'file_name': 'app.py', 'file_type': '.py'}, page_content='from flask import Flask, render_template, jsonify, request\\r\\nfrom src.helper import download_hugging_face_embeddings\\r\\nfrom langchain_pinecone import PineconeVectorStore\\r\\nfrom langchain_openai import OpenAI\\r\\nfrom langchain.chains import create_retrieval_chain\\r\\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\\r\\nfrom langchain_core.prompts import ChatPromptTemplate\\r\\nfrom dotenv import load_dotenv\\r\\nfrom src.prompt import *\\r\\nimport os\\r\\n\\r\\napp = Flask(__name__)\\r\\n\\r\\nload_dotenv()\\r\\n\\r\\nPINECONE_API_KEY=os.environ.get(\\'PINECONE_API_KEY\\')\\r\\nOPENAI_API_KEY=os.environ.get(\\'OPENAI_API_KEY\\')\\r\\n\\r\\nos.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\\r\\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\\r\\n\\r\\nembeddings = download_hugging_face_embeddings()\\r\\n\\r\\n\\r\\nindex_name = \"bodybuildingchatbot\"\\r\\n\\r\\n# Embed each chunk and upsert the embeddings into your Pinecone index.\\r\\ndocsearch = PineconeVectorStore.from_existing_index(\\r\\n    index_name=index_name,\\r\\n    embedding=embeddings\\r\\n)\\r\\n\\r\\nretriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\\r\\n\\r\\n\\r\\nllm = OpenAI(temperature=0.4, max_tokens=500)\\r\\nprompt = ChatPromptTemplate.from_messages(\\r\\n    [\\r\\n        (\"system\", system_prompt),\\r\\n        (\"human\", \"{input}\"),\\r\\n    ]\\r\\n)\\r\\n\\r\\nquestion_answer_chain = create_stuff_documents_chain(llm, prompt)\\r\\nrag_chain = create_retrieval_chain(retriever, question_answer_chain)\\r\\n\\r\\n\\r\\n@app.route(\"/\")\\r\\ndef index():\\r\\n    return render_template(\\'chat.html\\')\\r\\n\\r\\n\\r\\n@app.route(\"/get\", methods=[\"GET\", \"POST\"]) \\r\\ndef chat():\\r\\n    msg = request.form[\"msg\"]\\r\\n    input = msg\\r\\n    print(input)\\r\\n    response = rag_chain.invoke({\"input\": msg})\\r\\n    print(\"Response : \", response[\"answer\"])\\r\\n    return str(response[\"answer\"])\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nif __name__ == \\'__main__\\':\\r\\n    app.run(host=\"0.0.0.0\", port= 8080, debug= True)\\r\\n'),\n",
       " Document(metadata={'source': 'requirements.txt', 'file_path': 'requirements.txt', 'file_name': 'requirements.txt', 'file_type': '.txt'}, page_content='sentence-transformers\\r\\nlangchain\\r\\nflask\\r\\npypdf\\r\\npython-dotenv\\r\\npinecone\\r\\nlangchain-pinecone\\r\\nlangchain-huggingface\\r\\nlangchain_community\\r\\nlangchain_openai\\r\\nlangchain_experimental\\r\\n-e .'),\n",
       " Document(metadata={'source': 'setup.py', 'file_path': 'setup.py', 'file_name': 'setup.py', 'file_type': '.py'}, page_content=\"from setuptools import find_packages, setup\\r\\n\\r\\nsetup(\\r\\n    name = 'BodyScienceLLM',\\r\\n    version= '0.0.0',\\r\\n    author= 'Tarang Nair',\\r\\n    author_email= 'tarangnair98@gmail.com',\\r\\n    packages= find_packages(),\\r\\n    install_requires = []\\r\\n)\"),\n",
       " Document(metadata={'source': 'store_index.py', 'file_path': 'store_index.py', 'file_name': 'store_index.py', 'file_type': '.py'}, page_content='from src.helper import load_pdf_file, text_split, download_hugging_face_embeddings\\r\\nfrom pinecone import Pinecone,ServerlessSpec\\r\\nfrom langchain_pinecone import PineconeVectorStore\\r\\nfrom dotenv import load_dotenv\\r\\nimport os\\r\\n\\r\\n\\r\\nload_dotenv()\\r\\n\\r\\nPINECONE_API_KEY=os.environ.get(\\'PINECONE_API_KEY\\')\\r\\nos.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\\r\\n\\r\\n\\r\\nextracted_data=load_pdf_file(data=\\'data/\\')\\r\\ntext_chunks=text_split(extracted_data)\\r\\nembeddings = download_hugging_face_embeddings()\\r\\n\\r\\n\\r\\npc = Pinecone(api_key=PINECONE_API_KEY)\\r\\n\\r\\nindex_name = \"bodybuildingchatbot\"\\r\\n\\r\\n\\r\\npc.create_index(\\r\\n    name=index_name,\\r\\n    dimension=384,  # Output Dimensions From the embedding model \\r\\n    metric=\"cosine\", \\r\\n    spec=ServerlessSpec(\\r\\n        cloud=\"aws\", \\r\\n        region=\"us-east-1\"\\r\\n    ) \\r\\n) \\r\\n\\r\\n# Embed each chunk and upsert the embeddings into your Pinecone index.\\r\\ndocsearch = PineconeVectorStore.from_documents(\\r\\n    documents=text_chunks,\\r\\n    index_name=index_name,\\r\\n    embedding=embeddings, \\r\\n)\\r\\n'),\n",
       " Document(metadata={'source': 'template.py', 'file_path': 'template.py', 'file_name': 'template.py', 'file_type': '.py'}, page_content='import os\\r\\nfrom pathlib import Path\\r\\nimport logging\\r\\n\\r\\nlogging.basicConfig(level=logging.INFO, format=\\'[%(asctime)s]: %(message)s:\\')\\r\\n\\r\\n\\r\\nlist_of_files = [\\r\\n    \"src/__init__.py\",\\r\\n    \"src/helper.py\",\\r\\n    \"src/prompt.py\",\\r\\n    \".env\",\\r\\n    \"setup.py\",\\r\\n    \"app.py\",\\r\\n    \"research/trials.ipynb\",\\r\\n]\\r\\n\\r\\n\\r\\nfor filepath in list_of_files:\\r\\n    filepath = Path(filepath)\\r\\n    filedir, filename = os.path.split(filepath)\\r\\n\\r\\n\\r\\n    if filedir !=\"\":\\r\\n        os.makedirs(filedir, exist_ok=True)\\r\\n        logging.info(f\"Creating directory; {filedir} for the file: {filename}\")\\r\\n\\r\\n    if (not os.path.exists(filepath)) or (os.path.getsize(filepath) == 0):\\r\\n        with open(filepath, \"w\") as f:\\r\\n            pass\\r\\n            logging.info(f\"Creating empty file: {filepath}\")\\r\\n\\r\\n\\r\\n    else:\\r\\n        logging.info(f\"{filename} is already exists\")'),\n",
       " Document(metadata={'source': 'src\\\\__init__.py', 'file_path': 'src\\\\__init__.py', 'file_name': '__init__.py', 'file_type': '.py'}, page_content=''),\n",
       " Document(metadata={'source': 'src\\\\helper.py', 'file_path': 'src\\\\helper.py', 'file_name': 'helper.py', 'file_type': '.py'}, page_content='\\r\\nfrom langchain_community.document_loaders import DirectoryLoader\\r\\nfrom langchain_community.document_loaders import PyPDFLoader\\r\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\r\\nfrom langchain_huggingface import HuggingFaceEmbeddings\\r\\n\\r\\n\\r\\n\\r\\n#Extract Data From the PDF File\\r\\ndef load_pdf_file(data):\\r\\n    loader= DirectoryLoader(data,\\r\\n                            glob=\"*.pdf\",\\r\\n                            loader_cls=PyPDFLoader)\\r\\n\\r\\n    documents=loader.load()\\r\\n\\r\\n    return documents\\r\\n\\r\\n\\r\\n\\r\\n#Split the Data into Text Chunks\\r\\ndef text_split(extracted_data):\\r\\n    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\\r\\n    text_chunks=text_splitter.split_documents(extracted_data)\\r\\n    return text_chunks\\r\\n\\r\\n\\r\\n\\r\\n#Download the Embeddings from HuggingFace \\r\\ndef download_hugging_face_embeddings():\\r\\n    embeddings=HuggingFaceEmbeddings(model_name=\\'sentence-transformers/all-MiniLM-L6-v2\\')  #this model return 384 dimensions\\r\\n    return embeddings'),\n",
       " Document(metadata={'source': 'src\\\\prompt.py', 'file_path': 'src\\\\prompt.py', 'file_name': 'prompt.py', 'file_type': '.py'}, page_content='\\r\\n\\r\\nsystem_prompt = (\\r\\n    \"You are an assistant for question-answering tasks. \"\\r\\n    \"Use the following pieces of retrieved context to answer \"\\r\\n    \"the question. If you don\\'t know the answer, say that you \"\\r\\n    \"don\\'t know. Use three sentences maximum and keep the \"\\r\\n    \"answer concise.\"\\r\\n    \"\\\\n\\\\n\"\\r\\n    \"{context}\"\\r\\n)\\r\\n'),\n",
       " Document(metadata={'source': 'static\\\\style.css', 'file_path': 'static\\\\style.css', 'file_name': 'style.css', 'file_type': '.css'}, page_content='body,\\r\\nhtml {\\r\\n    height: 100%;\\r\\n    margin: 0;\\r\\n    background: rgb(44, 47, 59);\\r\\n    background: -webkit-linear-gradient(to right, rgb(40, 59, 34), rgb(54, 60, 70), rgb(32, 32, 43));\\r\\n    background: linear-gradient(to right, rgb(38, 51, 61), rgb(50, 55, 65), rgb(33, 33, 78));\\r\\n}\\r\\n\\r\\n.chat {\\r\\n    margin-top: auto;\\r\\n    margin-bottom: auto;\\r\\n}\\r\\n\\r\\n.card {\\r\\n    height: 500px;\\r\\n    border-radius: 15px !important;\\r\\n    background-color: rgba(0, 0, 0, 0.4) !important;\\r\\n}\\r\\n\\r\\n.contacts_body {\\r\\n    padding: 0.75rem 0 !important;\\r\\n    overflow-y: auto;\\r\\n    white-space: nowrap;\\r\\n}\\r\\n\\r\\n.msg_card_body {\\r\\n    overflow-y: auto;\\r\\n}\\r\\n\\r\\n.card-header {\\r\\n    border-radius: 15px 15px 0 0 !important;\\r\\n    border-bottom: 0 !important;\\r\\n}\\r\\n\\r\\n.card-footer {\\r\\n    border-radius: 0 0 15px 15px !important;\\r\\n    border-top: 0 !important;\\r\\n}\\r\\n\\r\\n.container {\\r\\n    align-content: center;\\r\\n}\\r\\n\\r\\n.search {\\r\\n    border-radius: 15px 0 0 15px !important;\\r\\n    background-color: rgba(0, 0, 0, 0.3) !important;\\r\\n    border: 0 !important;\\r\\n    color: white !important;\\r\\n}\\r\\n\\r\\n.search:focus {\\r\\n    box-shadow: none !important;\\r\\n    outline: 0px !important;\\r\\n}\\r\\n\\r\\n.type_msg {\\r\\n    background-color: rgba(0, 0, 0, 0.3) !important;\\r\\n    border: 0 !important;\\r\\n    color: white !important;\\r\\n    height: 60px !important;\\r\\n    overflow-y: auto;\\r\\n}\\r\\n\\r\\n.type_msg:focus {\\r\\n    box-shadow: none !important;\\r\\n    outline: 0px !important;\\r\\n}\\r\\n\\r\\n.attach_btn {\\r\\n    border-radius: 15px 0 0 15px !important;\\r\\n    background-color: rgba(0, 0, 0, 0.3) !important;\\r\\n    border: 0 !important;\\r\\n    color: white !important;\\r\\n    cursor: pointer;\\r\\n}\\r\\n\\r\\n.send_btn {\\r\\n    border-radius: 0 15px 15px 0 !important;\\r\\n    background-color: rgba(0, 0, 0, 0.3) !important;\\r\\n    border: 0 !important;\\r\\n    color: white !important;\\r\\n    cursor: pointer;\\r\\n}\\r\\n\\r\\n.search_btn {\\r\\n    border-radius: 0 15px 15px 0 !important;\\r\\n    background-color: rgba(0, 0, 0, 0.3) !important;\\r\\n    border: 0 !important;\\r\\n    color: white !important;\\r\\n    cursor: pointer;\\r\\n}\\r\\n\\r\\n.contacts {\\r\\n    list-style: none;\\r\\n    padding: 0;\\r\\n}\\r\\n\\r\\n.contacts li {\\r\\n    width: 100% !important;\\r\\n    padding: 5px 10px;\\r\\n    margin-bottom: 15px !important;\\r\\n}\\r\\n\\r\\n.active {\\r\\n    background-color: rgba(0, 0, 0, 0.3);\\r\\n}\\r\\n\\r\\n.user_img {\\r\\n    height: 70px;\\r\\n    width: 70px;\\r\\n    border: 1.5px solid #f5f6fa;\\r\\n\\r\\n}\\r\\n\\r\\n.user_img_msg {\\r\\n    height: 40px;\\r\\n    width: 40px;\\r\\n    border: 1.5px solid #f5f6fa;\\r\\n\\r\\n}\\r\\n\\r\\n.img_cont {\\r\\n    position: relative;\\r\\n    height: 70px;\\r\\n    width: 70px;\\r\\n}\\r\\n\\r\\n.img_cont_msg {\\r\\n    height: 40px;\\r\\n    width: 40px;\\r\\n}\\r\\n\\r\\n.online_icon {\\r\\n    position: absolute;\\r\\n    height: 15px;\\r\\n    width: 15px;\\r\\n    background-color: #4cd137;\\r\\n    border-radius: 50%;\\r\\n    bottom: 0.2em;\\r\\n    right: 0.4em;\\r\\n    border: 1.5px solid white;\\r\\n}\\r\\n\\r\\n.offline {\\r\\n    background-color: #c23616 !important;\\r\\n}\\r\\n\\r\\n.user_info {\\r\\n    margin-top: auto;\\r\\n    margin-bottom: auto;\\r\\n    margin-left: 15px;\\r\\n}\\r\\n\\r\\n.user_info span {\\r\\n    font-size: 20px;\\r\\n    color: white;\\r\\n}\\r\\n\\r\\n.user_info p {\\r\\n    font-size: 10px;\\r\\n    color: rgba(255, 255, 255, 0.6);\\r\\n}\\r\\n\\r\\n.video_cam {\\r\\n    margin-left: 50px;\\r\\n    margin-top: 5px;\\r\\n}\\r\\n\\r\\n.video_cam span {\\r\\n    color: white;\\r\\n    font-size: 20px;\\r\\n    cursor: pointer;\\r\\n    margin-right: 20px;\\r\\n}\\r\\n\\r\\n.msg_cotainer {\\r\\n    margin-top: auto;\\r\\n    margin-bottom: auto;\\r\\n    margin-left: 10px;\\r\\n    border-radius: 25px;\\r\\n    background-color: rgb(82, 172, 255);\\r\\n    padding: 10px;\\r\\n    position: relative;\\r\\n}\\r\\n\\r\\n.msg_cotainer_send {\\r\\n    margin-top: auto;\\r\\n    margin-bottom: auto;\\r\\n    margin-right: 10px;\\r\\n    border-radius: 25px;\\r\\n    background-color: #58cc71;\\r\\n    padding: 10px;\\r\\n    position: relative;\\r\\n}\\r\\n\\r\\n.msg_time {\\r\\n    position: absolute;\\r\\n    left: 0;\\r\\n    bottom: -15px;\\r\\n    color: rgba(255, 255, 255, 0.5);\\r\\n    font-size: 10px;\\r\\n}\\r\\n\\r\\n.msg_time_send {\\r\\n    position: absolute;\\r\\n    right: 0;\\r\\n    bottom: -15px;\\r\\n    color: rgba(255, 255, 255, 0.5);\\r\\n    font-size: 10px;\\r\\n}\\r\\n\\r\\n.msg_head {\\r\\n    position: relative;\\r\\n}\\r\\n\\r\\n#action_menu_btn {\\r\\n    position: absolute;\\r\\n    right: 10px;\\r\\n    top: 10px;\\r\\n    color: white;\\r\\n    cursor: pointer;\\r\\n    font-size: 20px;\\r\\n}\\r\\n\\r\\n.action_menu {\\r\\n    z-index: 1;\\r\\n    position: absolute;\\r\\n    padding: 15px 0;\\r\\n    background-color: rgba(0, 0, 0, 0.5);\\r\\n    color: white;\\r\\n    border-radius: 15px;\\r\\n    top: 30px;\\r\\n    right: 15px;\\r\\n    display: none;\\r\\n}\\r\\n\\r\\n.action_menu ul {\\r\\n    list-style: none;\\r\\n    padding: 0;\\r\\n    margin: 0;\\r\\n}\\r\\n\\r\\n.action_menu ul li {\\r\\n    width: 100%;\\r\\n    padding: 10px 15px;\\r\\n    margin-bottom: 5px;\\r\\n}\\r\\n\\r\\n.action_menu ul li i {\\r\\n    padding-right: 10px;\\r\\n}\\r\\n\\r\\n.action_menu ul li:hover {\\r\\n    cursor: pointer;\\r\\n    background-color: rgba(0, 0, 0, 0.2);\\r\\n}\\r\\n\\r\\n@media(max-width: 576px) {\\r\\n    .contacts_card {\\r\\n        margin-bottom: 15px !important;\\r\\n    }\\r\\n}'),\n",
       " Document(metadata={'source': 'templates\\\\chat.html', 'file_path': 'templates\\\\chat.html', 'file_name': 'chat.html', 'file_type': '.html'}, page_content='<link href=\"//maxcdn.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css\" rel=\"stylesheet\" id=\"bootstrap-css\">\\r\\n<script src=\"//maxcdn.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js\"></script>\\r\\n<script src=\"//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js\"></script>\\r\\n\\r\\n<!DOCTYPE html>\\r\\n<html>\\r\\n\\r\\n<head>\\r\\n    <title>Chatbot</title>\\r\\n    <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css\"\\r\\n        integrity=\"sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\" crossorigin=\"anonymous\">\\r\\n    <link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.5.0/css/all.css\"\\r\\n        integrity=\"sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU\" crossorigin=\"anonymous\">\\r\\n    <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\\r\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"{{ url_for(\\'static\\', filename=\\'style.css\\')}}\" />\\r\\n</head>\\r\\n\\r\\n\\r\\n<body>\\r\\n    <div class=\"container-fluid h-100\">\\r\\n        <div class=\"row justify-content-center h-100\">\\r\\n            <div class=\"col-md-8 col-xl-6 chat\">\\r\\n                <div class=\"card\">\\r\\n                    <div class=\"card-header msg_head\">\\r\\n                        <div class=\"d-flex bd-highlight\">\\r\\n                            <div class=\"img_cont\">\\r\\n                                <img src=\"https://static.vecteezy.com/system/resources/previews/013/699/442/non_2x/fitness-and-bodybuilding-logo-design-inspiration-template-vector.jpg\"\\r\\n                                    class=\"rounded-circle user_img\">\\r\\n                                <span class=\"online_icon\"></span>\\r\\n                            </div>\\r\\n                            <div class=\"user_info\">\\r\\n                                <span>Body Building Chatbot</span>\\r\\n                                <p>Ask me anything about body building!</p>\\r\\n                            </div>\\r\\n                        </div>\\r\\n                    </div>\\r\\n                    <div id=\"messageFormeight\" class=\"card-body msg_card_body\">\\r\\n\\r\\n\\r\\n                    </div>\\r\\n                    <div class=\"card-footer\">\\r\\n                        <form id=\"messageArea\" class=\"input-group\">\\r\\n                            <input type=\"text\" id=\"text\" name=\"msg\" placeholder=\"Type your message...\"\\r\\n                                autocomplete=\"off\" class=\"form-control type_msg\" required />\\r\\n                            <div class=\"input-group-append\">\\r\\n                                <button type=\"submit\" id=\"send\" class=\"input-group-text send_btn\"><i\\r\\n                                        class=\"fas fa-location-arrow\"></i></button>\\r\\n                            </div>\\r\\n                        </form>\\r\\n                    </div>\\r\\n                </div>\\r\\n            </div>\\r\\n        </div>\\r\\n    </div>\\r\\n\\r\\n    <script>\\r\\n        $(document).ready(function () {\\r\\n            $(\"#messageArea\").on(\"submit\", function (event) {\\r\\n                const date = new Date();\\r\\n                const hour = date.getHours();\\r\\n                const minute = date.getMinutes();\\r\\n                const str_time = hour + \":\" + minute;\\r\\n                var rawText = $(\"#text\").val();\\r\\n\\r\\n                var userHtml = \\'<div class=\"d-flex justify-content-end mb-4\"><div class=\"msg_cotainer_send\">\\' + rawText + \\'<span class=\"msg_time_send\">\\' + str_time + \\'</span></div><div class=\"img_cont_msg\"><img src=\"https://i.ibb.co/d5b84Xw/Untitled-design.png\" class=\"rounded-circle user_img_msg\"></div></div>\\';\\r\\n\\r\\n                $(\"#text\").val(\"\");\\r\\n                $(\"#messageFormeight\").append(userHtml);\\r\\n\\r\\n                $.ajax({\\r\\n                    data: {\\r\\n                        msg: rawText,\\r\\n                    },\\r\\n                    type: \"POST\",\\r\\n                    url: \"/get\",\\r\\n                }).done(function (data) {\\r\\n                    var botHtml = \\'<div class=\"d-flex justify-content-start mb-4\"><div class=\"img_cont_msg\"><img src=\"https://static.vecteezy.com/system/resources/previews/013/699/442/non_2x/fitness-and-bodybuilding-logo-design-inspiration-template-vector.jpg\" class=\"rounded-circle user_img_msg\"></div><div class=\"msg_cotainer\">\\' + data + \\'<span class=\"msg_time\">\\' + str_time + \\'</span></div></div>\\';\\r\\n                    $(\"#messageFormeight\").append($.parseHTML(botHtml));\\r\\n                });\\r\\n                event.preventDefault();\\r\\n            });\\r\\n        });\\r\\n    </script>\\r\\n\\r\\n</body>\\r\\n\\r\\n</html>')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load with GitLoader first\n",
    "git_loader = GitLoader(\n",
    "    \n",
    "    repo_path= repo_path,\n",
    "    clone_url= repo_link,\n",
    "    branch = \"main\",\n",
    "    file_filter=create_language_filter()  # All languages\n",
    ")\n",
    "\n",
    "# Load documents\n",
    "documents = git_loader.load()\n",
    "documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using language-specific text splitter :  {'source': ' test.py', 'file_path': ' test.py', 'file_name': ' test.py', 'file_type': '.py'}\n",
      "Using default text splitter :  {'source': 'README.md', 'file_path': 'README.md', 'file_name': 'README.md', 'file_type': '.md'}\n",
      "Using language-specific text splitter :  {'source': 'app.py', 'file_path': 'app.py', 'file_name': 'app.py', 'file_type': '.py'}\n",
      "Using default text splitter :  {'source': 'requirements.txt', 'file_path': 'requirements.txt', 'file_name': 'requirements.txt', 'file_type': '.txt'}\n",
      "Using language-specific text splitter :  {'source': 'setup.py', 'file_path': 'setup.py', 'file_name': 'setup.py', 'file_type': '.py'}\n",
      "Using language-specific text splitter :  {'source': 'store_index.py', 'file_path': 'store_index.py', 'file_name': 'store_index.py', 'file_type': '.py'}\n",
      "Using language-specific text splitter :  {'source': 'template.py', 'file_path': 'template.py', 'file_name': 'template.py', 'file_type': '.py'}\n",
      "Using language-specific text splitter :  {'source': 'src\\\\__init__.py', 'file_path': 'src\\\\__init__.py', 'file_name': '__init__.py', 'file_type': '.py'}\n",
      "Using language-specific text splitter :  {'source': 'src\\\\helper.py', 'file_path': 'src\\\\helper.py', 'file_name': 'helper.py', 'file_type': '.py'}\n",
      "Using language-specific text splitter :  {'source': 'src\\\\prompt.py', 'file_path': 'src\\\\prompt.py', 'file_name': 'prompt.py', 'file_type': '.py'}\n",
      "Using default text splitter :  {'source': 'static\\\\style.css', 'file_path': 'static\\\\style.css', 'file_name': 'style.css', 'file_type': '.css'}\n",
      "Using default text splitter :  {'source': 'templates\\\\chat.html', 'file_path': 'templates\\\\chat.html', 'file_name': 'chat.html', 'file_type': '.html'}\n",
      "\n",
      "Total documents loaded: 12\n",
      "Total chunks created: 39\n",
      "Files processed:\n",
      "  -  test.py (.py)\n",
      "  - README.md (.md)\n",
      "  - app.py (.py)\n",
      "  - requirements.txt (.txt)\n",
      "  - setup.py (.py)\n",
      "  - store_index.py (.py)\n",
      "  - template.py (.py)\n",
      "  - src\\__init__.py (.py)\n",
      "  - src\\helper.py (.py)\n",
      "  - src\\prompt.py (.py)\n",
      "  - static\\style.css (.css)\n",
      "  - templates\\chat.html (.html)\n"
     ]
    }
   ],
   "source": [
    "# Process documents with language-specific parsing + fallback\n",
    "processed_docs = []\n",
    "\n",
    "for doc in documents:\n",
    "    file_ext = get_file_extension(doc.metadata.get('source', ''))\n",
    "    \n",
    "    # Determine language from file extension\n",
    "    language = None\n",
    "    for lang, value in SUPPORTED_LANGUAGES.items():\n",
    "        if file_ext in value[\"suffixes\"]:\n",
    "            language = lang\n",
    "            break\n",
    "    \n",
    "    # if language:\n",
    "    #     # Use language-specific parser for supported languages\n",
    "    #     # Makes code semantics explicit\n",
    "    #     # Improves AI understanding\n",
    "    #     # Enables better search and retrieval\n",
    "    #     # Facilitates code analysis\n",
    "    #     # Enhances documentation generation\n",
    "    #     # Improves vector embeddings\n",
    "    #     # Enables precise code queries\n",
    "    #     try:\n",
    "    #         language_parser = LanguageParser(\n",
    "    #             language=language,\n",
    "    #             # parser_threshold=500\n",
    "    #         )\n",
    "    #         # Parse the content with language-specific parser\n",
    "    #         parsed_content = language_parser.parse(doc)\n",
    "    #         doc.page_content = parsed_content\n",
    "    #         print(f\"Used language parser for {file_ext}: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Language parser failed for {file_ext}, using default: {e}\")\n",
    "    #         # Fallback to default parsing (no change to content)\n",
    "    # else:\n",
    "    #     # Use default parsing for text files (no language parser)\n",
    "    #     print(f\"Using default parser for {file_ext}: {doc.metadata.get('source', 'Unknown')}\")\n",
    "\n",
    "    \n",
    "    # Apply text splitting (language-aware if possible, otherwise default)\n",
    "    # Language specific enables the parser to understand Python code structure (functions, classes, imports, etc.)\n",
    "    # It can intelligently split code based on Python syntax rather than just arbitrary text breaks\n",
    "    # The parser will try to break Python code at logical boundaries (like function definitions, class boundaries, etc.)\n",
    "    # Instead of breaking mid-function or mid-statement, it respects Python syntax\n",
    "    # Preserves context: Keeps related code together (e.g., a function and its docstring)\n",
    "    # Maintains structure: Respects Python's indentation and block structure\n",
    "    # Better embeddings: Creates more meaningful chunks for AI analysis\n",
    "    try:\n",
    "        if language:\n",
    "            # Use language-specific text splitter\n",
    "            text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "                language=language,\n",
    "                chunk_size=500,\n",
    "                chunk_overlap=20\n",
    "            )\n",
    "            print(\"Using language-specific text splitter : \", doc.metadata)\n",
    "        else:\n",
    "            # Use default text splitter for non-programming files\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=500,\n",
    "                chunk_overlap=20\n",
    "            )\n",
    "            print(\"Using default text splitter : \", doc.metadata)\n",
    "        \n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        processed_docs.extend(chunks)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Text splitting failed for {file_ext}, using default: {e}\")\n",
    "        # Fallback to default text splitting\n",
    "        default_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=20\n",
    "        )\n",
    "        chunks = default_splitter.split_documents([doc])\n",
    "        processed_docs.extend(chunks)\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")\n",
    "print(f\"Total chunks created: {len(processed_docs)}\")\n",
    "print(f\"Files processed:\")\n",
    "for doc in documents:\n",
    "    file_path = doc.metadata.get('source', 'Unknown')\n",
    "    file_ext = get_file_extension(file_path)\n",
    "    print(f\"  - {file_path} ({file_ext})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.environ.get('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectordb = Chroma.from_documents(processed_docs, embedding=embeddings, persist_directory='./db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(model_name=\"gpt-4\")\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a memory class from LangChain that keeps track of the conversation history, \n",
    "# but instead of storing the entire chat log, it stores a summary of the conversation so far. \n",
    "# This is useful for long conversations where you want to keep context but not overload the model with too much text.\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a chain that:\n",
    "# Accepts user questions\n",
    "# Retrieves relevant documents from a vector database\n",
    "# Uses an LLM to generate answers, considering both the retrieved documents and the conversation history\n",
    "\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    # MMR stands for Maximum Marginal Relevance.\n",
    "    # Instead of fetching the most similar documents outright (like normal similarity search), MMR balances:\n",
    "    # Relevance to your query.\n",
    "    # Diversity among returned documents.\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":8}), \n",
    "    memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `download_hugging_face_embeddings` function is defined in the code to download embeddings using the Hugging Face model called 'sentence-transformers/all-MiniLM-L6-v2'. This function returns the embeddings generated by the specified Hugging Face model, which typically has 384 dimensions.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is download_hugging_face_embeddings funtion?\"\n",
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of the `load_pdf_file` function is to extract data from PDF files. It uses a directory loader to load PDF documents and returns the extracted documents.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is load_pdf_file funtion?\"\n",
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
